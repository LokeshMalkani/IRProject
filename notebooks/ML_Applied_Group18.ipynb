{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Applied.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ld1_rzvJod8T",
        "QbZsme1Boo_c",
        "MVul7HRFo5O7",
        "qjMqpXjHo8Vv",
        "aR9M4BVP6cT1",
        "TbULfT5LCQqr"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld1_rzvJod8T"
      },
      "source": [
        "#Import Section:\n",
        "-----------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik0hu3MM_3zJ",
        "outputId": "07d5d84f-19b8-41cd-c6cd-5bc012dbdbd6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbZsme1Boo_c"
      },
      "source": [
        "# Installs & Downloads:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqDqWAbnJ_hg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE6v3dgaostF",
        "outputId": "a37f79e4-66de-4cf3-a00f-9033209b744b"
      },
      "source": [
        "!pip install demoji\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting demoji\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6a/34379abe01c9c36fe9fddc4181dd935332e7d0159ec3fae76f712e49bcea/demoji-0.4.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.7/dist-packages (from demoji) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0->demoji) (2020.12.5)\n",
            "Installing collected packages: colorama, demoji\n",
            "Successfully installed colorama-0.4.4 demoji-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a2Wzyc_oZpl",
        "outputId": "c2531e9a-968e-487f-d31f-b07fd8eec9f1"
      },
      "source": [
        "import gensim\n",
        "import nltk\n",
        "import numpy\n",
        "import tensorflow\n",
        "import torch\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.callbacks import *\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import matplotlib.pyplot as plt \n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, LSTM, GRU, Conv1D, MaxPooling1D, Concatenate  ,SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.models import Sequential \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import glob\n",
        "%matplotlib inline\n",
        "import demoji\n",
        "import nltk\n",
        "\n",
        "\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.util import ngrams\n",
        "import collections\n",
        "import nltk\n",
        "from collections import Counter\n",
        "import re\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.sentiment import vader\n",
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from nltk.corpus import stopwords\n",
        "demoji.download_codes()\n",
        "\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading emoji data ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... OK (Got response in 0.54 seconds)\n",
            "Writing emoji data to /root/.demoji/codes.json ...\n",
            "... OK\n",
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVul7HRFo5O7"
      },
      "source": [
        "#Helpers:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "LZwALJtVo6c_"
      },
      "source": [
        "#@title Default title text\n",
        "# def count_hashTag(listOfPreProcessSent):\n",
        "#   dicFinalLists =[{\"hasTagCount\":len(re.findall('\\B#\\w\\w+',text))} for text in listOfPreProcessSent]\n",
        "#   final_df = pd.DataFrame(dicFinalLists)\n",
        "#   return final_df\n",
        "#   \"\"\"Count the Hashss Tags Heres\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# #---------------------------------------------COUNT Punctuations--------------------------------------------------\n",
        "\n",
        "# def countPnct(listOfPreProcessSent):\n",
        "#     \"\"\"Count the Pnctutaions Tags Heres\"\"\"\n",
        "#     dicFinalLists =[{\"pncICount\":len(re.findall(r'\\B[?|!]*([?!])\\B', text))} for text in listOfPreProcessSent]\n",
        "#     final_df = pd.DataFrame(dicFinalLists)\n",
        "#     return final_df\n",
        "    \n",
        "#     # min. 2 or more\n",
        "\n",
        "# # \"\"\"Mathes: :( :) :P :p :O :3 :| :/ :\\ :$ :* :@\n",
        "# # :-( :-) :-P :-p :-O :-3 :-| :-/ :-\\ :-$ :-* :-@\n",
        "# # :^( :^) :^P :^p :^O :^3 :^| :^/ :^\\ :^$ :^* :^@\n",
        "# # ): (: $: *:\n",
        "# # )-: (-: $-: *-:\n",
        "# # )^: (^: $^: *^:\n",
        "# # <3 </3 <\\3\n",
        "# # :smile: :hug: :pencil:\"\"\"    \n",
        "# def countEmoticons(text):\n",
        "#     POSITIVE = [\"*O\", \"*-*\", \"*O*\", \"*o*\", \"* *\",\n",
        "#                 \":P\", \":D\", \":d\", \":p\",\n",
        "#                 \";P\", \";D\", \";d\", \";p\",\n",
        "#                 \":-)\", \";-)\", \":=)\", \";=)\",\n",
        "#                 \":<)\", \":>)\", \";>)\", \";=)\",\n",
        "#                 \"=}\", \":)\", \"(:;)\",\n",
        "#                 \"(;\", \":}\", \"{:\", \";}\",\n",
        "#                 \"{;:]\",\n",
        "#                 \"[;\", \":')\", \";')\", \":-3\",\n",
        "#                 \"{;\", \":]\",\n",
        "#                 \";-3\", \":-x\", \";-x\", \":-X\",\n",
        "#                 \";-X\", \":-}\", \";-=}\", \":-]\",\n",
        "#                 \";-]\", \":-.)\",\n",
        "#                 \"^_^\", \"^-^\"]\n",
        "\n",
        "#     NEGATIVE = [\":(\", \";(\", \":'(\",\n",
        "#                 \"=(\", \"={\", \"):\", \");\",\n",
        "#                 \")':\", \")';\", \")=\", \"}=\",\n",
        "#                 \";-{{\", \";-{\", \":-{{\", \":-{\",\n",
        "#                 \":-(\", \";-(\",\n",
        "#                 \":,)\", \":'{\",\n",
        "#                 \"[:\", \";]\"\n",
        "#                 ]\n",
        "#     emoticon_string = r\"\"\"\n",
        "#       (?:\n",
        "#         [<>]?\n",
        "#         [:;=8]                     # eyes\n",
        "#         [\\-o\\*\\']?                 # optional nose\n",
        "#         [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth      \n",
        "#         |\n",
        "#         [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
        "#         [\\-o\\*\\']?                 # optional nose\n",
        "#         [:;=8]                     # eyes\n",
        "#         [<>]?\n",
        "#       )\"\"\"            \n",
        "#     emoticon_re = re.compile(emoticon_string, re.VERBOSE | re.I | re.UNICODE)\n",
        "#     \"\"\"Count the Emoticons Tags Heres from Christopher regex\"\"\"\n",
        "#     emoticonList=re.findall(emoticon_re,text)\n",
        "       \n",
        "#     posList=[e for e in emoticonList if e in POSITIVE] \n",
        "#     negList=[e for e in emoticonList if e in NEGATIVE]\n",
        "#     lastOne=0\n",
        "#     # print(text.split())\n",
        "#     lastText=text.split()[-1]\n",
        "#     if len(emoticonList)>0 and lastText in emoticonList:\n",
        "#         if (emoticonList[-1]) in posList:\n",
        "#             lastOne=1#Possitive\n",
        "#         else:\n",
        "#             lastOne=-1#Negetive\n",
        "#     #\"Positive\":\"Negative\":\"Last\":\n",
        "#     return  pd.Series(np.array([len(posList),len(negList),lastOne]))\n",
        "# def countElongated(listOfPreProcessSent):\n",
        "#     \"\"\"Count the Elongateds Tags Heres\"\"\"\n",
        "\n",
        "#     dicFinalLists =[{\"elongatedCount\":len(re.findall(r'(\\w*)(\\w+)(\\2)(\\w*)', text))} for text in listOfPreProcessSent]\n",
        "#     final_df = pd.DataFrame(dicFinalLists)\n",
        "#     return final_df\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSGbwhkdSGcA"
      },
      "source": [
        "# dict_sad={\":-(\":\"SAD\", \":(\":\"SAD\", \":-|\":\"SAD\",  \";-(\":\"SAD\", \";-<\":\"SAD\", \"|-{\":\"SAD\"}\n",
        "# dict_happy={\":-)\":\"HAPPY\",\":)\":\"HAPPY\", \":o)\":\"HAPPY\",\":-}\":\"HAPPY\",\";-}\":\"HAPPY\",\":->\":\"HAPPY\",\";-)\":\"HAPPY\"}\n",
        "\n",
        "# #THE INPUT TEXT#\n",
        "# a=\"guys beautifully done :-)\" \n",
        "\n",
        "# for i in a.split():\n",
        "#     for j in dict_happy.keys():\n",
        "#         if set(j).issubset(set(i)):\n",
        "#             print \"HAPPY\"\n",
        "#             continue\n",
        "#     for k in dict_sad.keys():\n",
        "#         if set(k).issubset(set(i)):\n",
        "#             print \"SAD\"\n",
        "#             continue\n",
        "#     if str(i)==i.decode('utf-8','replace'):\n",
        "#        print i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sulRBCIFpKnc"
      },
      "source": [
        "\n",
        "# # def findTheEMoticons(text):\n",
        "# #   exactMatch = re.compile(ur\"([^\\.]*\\bтурција\\b[^\\.]*)\\.\", re.UNICODE)\n",
        "# #   print exactMatch.pattern\n",
        "# #   result= exactMatch.findall(u\"турција е на врвот од индустријата. турција е на врвот од индустријата.\")\n",
        "    \n",
        "#   # posList=len(re.findall( ru\"[\\U0001f600-\\U0001f650]\", text))\n",
        "#   # return pd.Series(np.array([len(posList)]))\n",
        "\n",
        "\n",
        "# import emoji\n",
        "\n",
        "# def extract_emojis(s):\n",
        "#   return ''.join(c for c in s if c in emoji.UNICODE_EMOJI)\n",
        "# # \n",
        "\n",
        "\n",
        "# demoji.replace_with_desc(\"game is on 🔥 🔥\", sep=\"\")#replace_with_desc(#\"game is on 🔥 🔥\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjMqpXjHo8Vv"
      },
      "source": [
        "#Preprocess:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4uSXEp7o-LV"
      },
      "source": [
        "#======================================================================================================\n",
        "                       \n",
        "                                       #PreProcessing\n",
        "\n",
        "#==============================================================================================\n",
        "def replaceElongated(word):\n",
        "    \"\"\" Replaces an elongated word with its basic form, unless the word exists in the lexicon(In Most Cases Working) \"\"\"\n",
        "\n",
        "    repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "    repl = r'\\1\\2\\3'\n",
        "    if wordnet.synsets(word):\n",
        "        return word\n",
        "    repl_word = repeat_regexp.sub(repl, word)\n",
        "    if repl_word != word:      \n",
        "        return replaceElongated(repl_word)\n",
        "    else:       \n",
        "        return repl_word\n",
        "\n",
        "def doPreProcess(text):\n",
        "\n",
        "   # ----------------------[1.    Demoji]----------------------------------------------\n",
        "  text=demoji.replace_with_desc(text, sep=\"\")# Repalce with text\n",
        "\n",
        "\n",
        "  #------------------------[2.   # and @ handling here]--------------------------------\n",
        "  #Eiether-------------------------------------------\n",
        "    # text=re.sub(\"([@#][A-Za-z0-9]+)\",\"\",text)#Replace by space those words with # and @\n",
        "\n",
        "      #Or\n",
        "  text=re.sub(\"([@#])\",\"\",text)#Replace by space the chars as  # and @\n",
        "  #-----------------------------------------------------------\n",
        "\n",
        "\n",
        "  #------------------------[3.    Remove the Links]--------------------------------\n",
        "  text=re.sub(r\"http\\S+\", \"\", text)#Remove the Links\n",
        " \n",
        "\n",
        "  #-------------------------[4.   Emoticons Replacement with text]-------------------\n",
        "  \n",
        "\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  words=WhitespaceTokenizer().tokenize(text.lower())#tokenizer.tokenize(text)#Tokenize and casings\n",
        "  df = pd.read_excel('/content/drive/MyDrive/Scraped Tweets/Emoticons_Emojis_Text.xlsx',sheet_name='Sheet2',header=0,converters={'Emoji':str,'Text':str,'Emoticons':str})\n",
        "  dictOfEmoticons=df.set_index('Emoji')['Text'].to_dict()\n",
        "  words=[dictOfEmoticons.get(x) if x in dictOfEmoticons.keys() else x for x in words]\n",
        "  text=' '.join(words)\n",
        "\n",
        "\n",
        "\n",
        "  #----------------------[5.       Ignore Non Ascii Characters]-----------------------\n",
        "  encoded_string = text.encode(\"ascii\", \"ignore\")  #For ASCII Onlys\n",
        "  text = encoded_string.decode()\n",
        "\n",
        "  #----------------------[6.       Single Quotes Handling Here Removal]---------------------:\n",
        "  text=text.translate(str.maketrans(\"\",\"\", \"'\"))\n",
        "  # text=text.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
        "\n",
        "\n",
        "  #---------------------[7.         Tokenizes]----------------------\n",
        "  # tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  words=WhitespaceTokenizer().tokenize(text)\n",
        " \n",
        "  #---------------------[8.         Lower Case Folding]------------------------------\n",
        "  # words=tokenizer.tokenize(text.lower())#Tokenize and casings\n",
        "\n",
        "  #---------------------[9.         Replace Elongated Words]-------------------------------\n",
        "\n",
        "  words=[replaceElongated(x) if not wordnet.synsets(x) else x for x in  words]\n",
        "\n",
        "\n",
        "\n",
        "  #---------------------[10. & 11.        Stopwords Removal & Lematize]--------------------------------------------- \n",
        "  wnl = WordNetLemmatizer() \n",
        "  words=[wnl.lemmatize(word) for word in words]\n",
        "  words=[word for word in words if word not in stopwords.words('english') ]\n",
        "\n",
        "  finalText= ' '.join(words)\n",
        "\n",
        "  #-------------------[11.                 Pnctations Removal]------------------------------\n",
        "  return re.sub(r'[^\\w\\s]', '',finalText)\n",
        "\n",
        "\n",
        "def preProcessing(df):\n",
        "  \n",
        "  df=df[['Text']]['Text'].apply(doPreProcess)\n",
        "  return df\n",
        "\n",
        "#======================================================================================================\n",
        "                       \n",
        "                                       #Global Data Frames\n",
        "\n",
        "#==============================================================================================\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR9M4BVP6cT1"
      },
      "source": [
        "#Run Here:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdWDkrA26bdG"
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Scraped Tweets/Copy of to_label_finished.csv\")\n",
        "df['Preprocessed_tweets']=df['Text'].apply(doPreProcess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uiwy3wxzPe2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b121fb-76b4-430a-9db3-67210fca7ebc"
      },
      "source": [
        "df['Text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       ‼️GTA KISAAN EKTA CAR RALLY‼️\\n\\nSaturday Dece...\n",
              "1       Dear #Annadaata it’s been 6th consecutive day ...\n",
              "2       This actually broke my heart... An elderly Kis...\n",
              "3       When farmers              When farmers \\ndeman...\n",
              "4       .@nsui Rajasthan is encircling the houses of B...\n",
              "                              ...                        \n",
              "2643    AAP MLA @JarnailSinghAAP arrested for protesti...\n",
              "2644    This is a brutal and merciless attack by Modi ...\n",
              "2645    From the barbed wires\\n From the showers of wa...\n",
              "2646    Orders from above - use 'misguised' for #Farme...\n",
              "2647    AIKS is at the border with the Farmers. The Al...\n",
              "Name: Text, Length: 2648, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDmPbkXWcU5p"
      },
      "source": [
        "# df[\"Label\"]=df[\"Label\"].replace(\"ANTI_FARMER\",\"AF_PG\")\n",
        "# df[\"Label\"]=df[\"Label\"].replace(\"PRO_GOVT\",\"AF_PG\")\n",
        "# df[\"Label\"]=df[\"Label\"].replace(\"ANTI_GOVT\",\"AG_PF\")\n",
        "# df[\"Label\"]=df[\"Label\"].replace(\"PRO_FARMER\",\"AG_PF\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMDHCgMKGSYR",
        "outputId": "9fa674f3-956a-4fcd-a122-835f3ac3a6c5"
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "df.groupby('Label').Text.count().plot.bar(ylim=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAGlCAYAAADXv676AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcTUlEQVR4nO3df7RdZX3n8fcHIohSfklETUKDNeMUax0xUlo76MAMgtiGsepAnZIq09QpVhQV0c4Uf7QjLjuidDqsoSUjrmVBpWrSAQcp4CirgARBfsqQ4WciSATEH0gV/M4fZwcOl9zk5t7k7Pvc836tdVb2fp7nnPO966zcz332fs7eqSokSdLst0PfBUiSpKkxtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEbM67uAzdl7771r8eLFfZchSdLIXH311d+rqvmb6pvVob148WLWrFnTdxmSJI1Mkjsn6/PwuCRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEbM6ltzSltj8cnn913CdnXHqUf2XYKknjnTliSpEYa2JEmNMLQlSWrEFkM7ycok9yW5YRN970pSSfbu9pPk9CRrk1yX5IChscuT3No9lm/bH0OSpLlvKjPtTwGHT2xMsgg4DLhrqPkIYEn3WAGc0Y3dCzgF+DXgQOCUJHvOpHBJksbNFkO7qr4GPLCJrtOAk4AaalsGfLoGrgD2SPJc4NXARVX1QFU9CFzEJv4QkCRJk5vWOe0ky4D1VfWtCV0LgLuH9td1bZO1S5KkKdrq72kneQbwfgaHxre5JCsYHFpn33333R5vIUlSk6Yz0/4lYD/gW0nuABYC30zyHGA9sGho7MKubbL2p6iqM6tqaVUtnT9//jTKkyRpbtrq0K6q66vq2VW1uKoWMzjUfUBV3QusBo7tVpEfBDxUVfcAFwKHJdmzW4B2WNcmSZKmaCpf+ToHuBx4YZJ1SY7bzPALgNuAtcBfA38EUFUPAB8GruoeH+raJEnSFG3xnHZVHbOF/sVD2wUcP8m4lcDKraxPkiR1vCKaJEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqxBZDO8nKJPcluWGo7WNJvp3kuiRfTLLHUN/7kqxNckuSVw+1H961rU1y8rb/USRJmtumMtP+FHD4hLaLgF+pql8F/i/wPoAk+wNHAy/qnvPfk+yYZEfgr4AjgP2BY7qxkiRpirYY2lX1NeCBCW1fqapHu90rgIXd9jLg3Kr6p6q6HVgLHNg91lbVbVX1U+DcbqwkSZqibXFO+y3Al7vtBcDdQ33rurbJ2iVJ0hTNKLST/AnwKPCZbVMOJFmRZE2SNRs2bNhWLytJUvOmHdpJfh94LfCmqqqueT2waGjYwq5tsvanqKozq2ppVS2dP3/+dMuTJGnOmVZoJzkcOAn47ap6eKhrNXB0kp2T7AcsAb4BXAUsSbJfkp0YLFZbPbPSJUkaL/O2NCDJOcCrgL2TrANOYbBafGfgoiQAV1TVW6vqxiSfA25icNj8+Kp6rHudtwEXAjsCK6vqxu3w80iSNGdtMbSr6phNNJ+1mfF/Dvz5JtovAC7YquokSdLjvCKaJEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqxBZDO8nKJPcluWGoba8kFyW5tft3z649SU5PsjbJdUkOGHrO8m78rUmWb58fR5KkuWsqM+1PAYdPaDsZuLiqlgAXd/sARwBLuscK4AwYhDxwCvBrwIHAKRuDXpIkTc0WQ7uqvgY8MKF5GXB2t302cNRQ+6dr4ApgjyTPBV4NXFRVD1TVg8BFPPUPAUmStBnTPae9T1Xd023fC+zTbS8A7h4at65rm6xdkiRN0YwXolVVAbUNagEgyYoka5Ks2bBhw7Z6WUmSmjfd0P5ud9ib7t/7uvb1wKKhcQu7tsnan6KqzqyqpVW1dP78+dMsT5KkuWe6ob0a2LgCfDmwaqj92G4V+UHAQ91h9AuBw5Ls2S1AO6xrkyRJUzRvSwOSnAO8Ctg7yToGq8BPBT6X5DjgTuCN3fALgNcAa4GHgTcDVNUDST4MXNWN+1BVTVzcJkmSNmOLoV1Vx0zSdegmxhZw/CSvsxJYuVXVSZKkx3lFNEmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDViXt8FzCaLTz6/7xK2qztOPbLvEiRJM+BMW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJasSMQjvJO5PcmOSGJOckeXqS/ZJcmWRtks8m2akbu3O3v7brX7wtfgBJksbFtEM7yQLg7cDSqvoVYEfgaOCjwGlV9QLgQeC47inHAQ927ad14yRJ0hTN9PD4PGCXJPOAZwD3AIcA53X9ZwNHddvLun26/kOTZIbvL0nS2Jh2aFfVeuAvgLsYhPVDwNXA96vq0W7YOmBBt70AuLt77qPd+GdN9/0lSRo3Mzk8vieD2fN+wPOAZwKHz7SgJCuSrEmyZsOGDTN9OUmS5oyZHB7/18DtVbWhqn4GfAF4BbBHd7gcYCGwvtteDywC6Pp3B+6f+KJVdWZVLa2qpfPnz59BeZIkzS0zCe27gIOSPKM7N30ocBNwKfD6bsxyYFW3vbrbp+u/pKpqBu8vSdJYmck57SsZLCj7JnB991pnAu8FTkyylsE567O6p5wFPKtrPxE4eQZ1S5I0dmZ0l6+qOgU4ZULzbcCBmxj7CPCGmbyfJEnjzCuiSZLUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1YkahnWSPJOcl+XaSm5P8epK9klyU5Nbu3z27sUlyepK1Sa5LcsC2+REkSRoPM51pfxL431X1z4GXADcDJwMXV9US4OJuH+AIYEn3WAGcMcP3liRprEw7tJPsDhwMnAVQVT+tqu8Dy4Czu2FnA0d128uAT9fAFcAeSZ477colSRozM5lp7wdsAP5nkmuS/E2SZwL7VNU93Zh7gX267QXA3UPPX9e1PUmSFUnWJFmzYcOGGZQnSdLcMpPQngccAJxRVS8FfswTh8IBqKoCamtetKrOrKqlVbV0/vz5MyhPkqS5ZSahvQ5YV1VXdvvnMQjx72487N39e1/Xvx5YNPT8hV2bJEmagmmHdlXdC9yd5IVd06HATcBqYHnXthxY1W2vBo7tVpEfBDw0dBhdkiRtwbwZPv+Pgc8k2Qm4DXgzgz8EPpfkOOBO4I3d2AuA1wBrgYe7sZIkaYpmFNpVdS2wdBNdh25ibAHHz+T9JEkaZ14RTZKkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEYY2pIkNWLGoZ1kxyTXJPlf3f5+Sa5MsjbJZ5Ps1LXv3O2v7foXz/S9JUkaJ9tipn0CcPPQ/keB06rqBcCDwHFd+3HAg137ad04SZI0RTMK7SQLgSOBv+n2AxwCnNcNORs4qtte1u3T9R/ajZckSVMw05n2J4CTgJ93+88Cvl9Vj3b764AF3fYC4G6Arv+hbrwkSZqCaYd2ktcC91XV1duwHpKsSLImyZoNGzZsy5eWJKlpM5lpvwL47SR3AOcyOCz+SWCPJPO6MQuB9d32emARQNe/O3D/xBetqjOramlVLZ0/f/4MypMkaW6ZdmhX1fuqamFVLQaOBi6pqjcBlwKv74YtB1Z126u7fbr+S6qqpvv+kiSNm+3xPe33AicmWcvgnPVZXftZwLO69hOBk7fDe0uSNGfN2/KQLauqrwJf7bZvAw7cxJhHgDdsi/eTJGkceUU0SZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaYWhLktSIeX0XIEkAi08+v+8Stps7Tj2y7xI0RzjTliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGTDu0kyxKcmmSm5LcmOSErn2vJBclubX7d8+uPUlOT7I2yXVJDthWP4QkSeNgJjPtR4F3VdX+wEHA8Un2B04GLq6qJcDF3T7AEcCS7rECOGMG7y1J0tiZdmhX1T1V9c1u+4fAzcACYBlwdjfsbOCobnsZ8OkauALYI8lzp125JEljZpuc006yGHgpcCWwT1Xd03XdC+zTbS8A7h562rquTZIkTcGMQzvJrsDfAe+oqh8M91VVAbWVr7ciyZokazZs2DDT8iRJmjNmFNpJnsYgsD9TVV/omr+78bB39+99Xft6YNHQ0xd2bU9SVWdW1dKqWjp//vyZlCdJ0pwyk9XjAc4Cbq6qjw91rQaWd9vLgVVD7cd2q8gPAh4aOowuSZK2YCa35nwF8HvA9Umu7dreD5wKfC7JccCdwBu7vguA1wBrgYeBN8/gvSVJGjvTDu2qugzIJN2HbmJ8AcdP9/0kSRp3XhFNkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjDG1JkhphaEuS1AhDW5KkRhjakiQ1wtCWJKkRhrYkSY0wtCVJaoShLUlSIwxtSZIaMe37aUuSBLD45PP7LmG7uuPUI/su4XHOtCVJaoShLUlSIwxtSZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiMMbUmSGmFoS5LUCENbkqRGGNqSJDXC0JYkqRGGtiRJjTC0JUlqhKEtSVIjRh7aSQ5PckuStUlOHvX7S5LUqpGGdpIdgb8CjgD2B45Jsv8oa5AkqVWjnmkfCKytqtuq6qfAucCyEdcgSVKTRh3aC4C7h/bXdW2SJGkL5vVdwERJVgArut0fJbmlz3q2s72B743qzfLRUb3T2PDza5efXdvm+uf3i5N1jDq01wOLhvYXdm2Pq6ozgTNHWVRfkqypqqV916Hp8fNrl59d28b58xv14fGrgCVJ9kuyE3A0sHrENUiS1KSRzrSr6tEkbwMuBHYEVlbVjaOsQZKkVo38nHZVXQBcMOr3naXG4jTAHObn1y4/u7aN7eeXquq7BkmSNAVexlSSpEYY2pIkNcLQliSpEYb2LJDkrr5rkCTNfob27JC+C9DmJdktyZKh/TckObZ77NNnbdqyJJ8a2l7eYynaSkl+M8mxQ/vnJbmkexzSZ219MLRnB5fwz35/AbxiaP8jwMuBg4EP9lKRtsZLhrZP6K0KTccHgTVD+y8E3gN8ADipj4L6NOuuPT5XJTlxsi5g11HWoml5OfCHQ/s/rKo/BkhyWT8laSv4h3G7dquqm4b2b62qqwGSfKSnmnpjaI/OL2ym75Mjq0LTNa+efFGD3xva3mPUxWirLUxyOoM/kjduP66q3t5PWZqCJ/3/qqrXDe2O3akpQ3tEqmrSQ6hJXj7KWjQtP0/ynKq6F6CqbgBIsgD4ea+VaSreM7S9ZtJRmo2+neTIqjp/uDHJa4G5fBfITTK0e5Jkf+CY7vF9YCzvWNOQjwF/n+RdwDVd2wEMznV/rLeqNCVVdfam2pM8HfitEZejrfNO4Pwkrwe+2bW9DPgN4LW9VdUTL2M6QkkW80RQ/4zBPVOXVtUd/VWlqUpyOPB+4EVd0w3AqVX15f6q0tZKsiPwagb/Dw8Dvl5Vr++3Km1Okp2BN/HE/70bgb+tqkf6q6ofhvaIJLkc2A04Fzi3qm5NcntV7ddzaZqBjTO1qvp837Vo85K8Evhd4DXANxh8G+D5VfVwr4VJW8HD46PzXWABg4UT84FbcUVrkzY1UwMM7VksyTrgLuAM4N1V9cPuj2YDe5ZLcjuT/66sqvqlUdbTN0N7RKrqqCS7A68DPtBdqGOPJAdW1Td6Lk9TMMlMbT9/8TfhPOAo4N8BjyVZhX80t2Liep8dgDcC7+aJ9SVjw8PjPUnybAa/QI4G9q2qRT2XpM2YMFP70tBMzdMbjUgS4FUMjpC8BtgdOA64oKp+1GNpmoIkOzD4quV7gGuB/zLh+9tjwdDuWZI9geOr6s/6rkWTS/IJBjO1G4C/BVYB11fV83stTNOS5Gk8cYrj1VW1d88laRLdZ/UWBqvIL2Ow+HNtv1X1x9AekSSLgP8MPA/4EnAO8CEGfzmeU1VeWnGWc6Y2NyXZpap+0m3/XVX9Tt816QndUa5HgU8wONr1JFX1hZEX1SNDe0SSXAr8H+By4PDucS3wzo0X7FA7nKnNTUmuqaqX9l2HntDd7GVzC9HeMsJyemdoj0iSb1XVS4b21zE4l+3VtBrnTG3uSPLNqjqg7zqkybh6fIS689cbb8N5P7B7d8iVqnqgt8I0IxsDu+M5bmkb2szNlgCoqo+PqpbZwNAend2Bq3nyvbM3XpKv8Jf9XOGhq7Z5b/vZZ3M3Wxq7/2+G9ui8sqru7LsISZv13r4L0FOsrKq7N9XR3TRkrOzQdwFj5It9F6CRcKY2CyVZluT4of0rk9zWPR6/7nhVfaWfCrUZF3X3bXiSJG9mDG9rbGiPjr/MG5Zk3ykOdaY2O50ErB7a3xl4OYOv8P3HPgrSlJ0IfKW7iiQASd7Xtb+yt6p64uHx0VmQ5PTJOqvq7aMsRlvtSwxuxbnZFeLO1GatnSYcYr2squ4H7k/yzL6K0pZV1QVJ/gn4cpKjgP8AHAgcXFUP9lvd6Bnao/MTBgvR1KbhIyUuGmzPnsM7VfW2od35I65FW6mqLu4Oh38V+EfgkHG8LScY2qN0f1Wd3XcRmraaZFttuDLJH1TVXw83JvlDBjd/0SyV5IcM/s+FwWmNQ4H7uq/LVlXt1md9o+bFVUYkyRVVdVDfdWh6kjwG/JjBL45dgI139hrLXxyt6W7Q8yXgn3jiq5YvYxACR1XVd/uqTdoahvaIJHkZT52tfW+yrzJI2vaSHAK8qNu9saou6bMeTV2Sf8UTn90NVfXVHsvpjaE9It21xyfaC9gJOKaqrh1xSdoKSZ4OvBV4AXAdg++OPtpvVZqqCZ/f9cBZfn5tSLIA+ALwCE+sC3oZgyNe/7aq1vdVWx8M7Z4lWQp8vKoO7rsWTS7JZ4GfAV8HjgDu9M5s7djE53dHVb2j36o0FUm+CKyqqk9NaD8W+J2qWtZLYT0xtGcBb1Iw+yW5vqpe3G3PA77hZ9YOP792Jbmlql64tX1zlRdX6VmSfXA1cgt+tnHDw6pN8vNr1yZzKskOwI4jrqV3zrRHJMlf8tRw3gv4DeCEqvr70VelqRpaPQ5PXkHu6vEG+Pm1K8lpwK7AO6rqx13bM4HTgEfG7cJUhvaIJFk+oakY3J7zqqq6r4eSJGnWS/I04CPA7wMbb7q0L3A28P6q+mlPpfXC0B6RJLtV1Q8m6du3qu4adU2SNNsleU5V3ZtkFwar/wH+X1U9vLnnzVWe0x6dr27cSHLxhL4vjbYUSWrGtUn+ATgGuLuqrh/XwAZDe5SGr12912b6JElPWAB8DPiXwC1JViU5upt5jx1De3Q2d+1qz1FI0iZU1WNVdWFVvRlYBKwElgG3J/lMv9WNnjcMGZ1nJzmRwax64zbdvncZkqQtqKqfJrkJuJnBVdF+ueeSRs6FaCOS5JTN9VfVB0dViyS1JMki4GgG57WfCZwDnFtV3+61sB4Y2pKkWSvJPzI4r/154JyqunoLT5nTDO0RSfKnm+muqvrwyIqRpEYkORj4elVVkl0BqupHPZfVGxeijc6PN/EAOA54b19FSdJsVlVfA96a5C4GF1e5K8mdSf6o59J64Uy7B0l+ATiBQWB/DvivXhVNkp4qyZ8ArwDeVlW3dW3PBz4JXFlVf9ZnfaNmaI9Qkr2AE4E3MbgE3yer6sF+q5Kk2SvJLcBLquqRCe27AN+qqn/WT2X98CtfI5LkY8DrgDOBF4/zORlJ2go1MbC7xp8k+XkfBfXJc9qj8y7gecB/Ar6T5Afd44dJNnlNckkS65McOrExySHAPT3U0ysPj0uSZq0kLwJWAZcBG7/utZTBee5lVXVjX7X1wdCWJM1qSZ4O/C7woq7pJuAzmzpsPtcZ2pKk5iTZATimqsbq+uOe05YkzVpJdkvyviT/Lcm/ycDbgNuAN/Zd36g505YkzVpJVgEPApcDhwLPZnCjpROq6to+a+uDoS1JmrWSXF9VL+62d2SwYnzfcTyfDR4elyTNbj/buFFVjwHrxjWwwZm2JGkWS/IYg3s1pGvaBXi426+q2q2v2vpgaEuS1AgvYypJmrW672i/FXgBcB2wsqoe7beq/jjTliTNWkk+y+C89teBI4A7q+qEfqvqj6EtSZq1Jqwenwd8o6oO6Lms3rh6XJI0mw2vHh/bw+IbOdOWJM1aQ6vHYbBi3NXjkiRp9vPwuCRJjTC0JUlqhKEtjYEkP9qKsR9I8u7t9fqSps/QliSpEYa2NKaS/FaSK5Nck+Qfkuwz1P2SJJcnuTXJHww95z1JrkpyXZIP9lC2NNYMbWl8XQYcVFUvBc4FThrq+1XgEODXgT9N8rwkhwFLgAOBfwG8LMnBI65ZGmtee1waXwuBzyZ5LrATcPtQ36qq+gnwkySXMgjq3wQOA67pxuzKIMS/NrqSpfFmaEvj6y+Bj1fV6iSvAj4w1DfxAg7F4GIWH6mq/zGa8iRN5OFxaXztDqzvtpdP6FuW5OlJngW8CrgKuBB4S5JdAZIsSPLsURUryZm2NC6ekWTd0P7HGcysP5/kQeASYL+h/uuAS4G9gQ9X1XeA7yT5ZeDyJAA/Av49cN/2L18SeBlTSZKa4eFxSZIaYWhLktQIQ1uSpEYY2pIkNcLQliSpEYa2JEmNMLQlSWqEoS1JUiP+P4kAVaSb0UaAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byKF1pYCGSNh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX-tSE0FGSCh"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp3MNdLORX3r"
      },
      "source": [
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from tqdm import tqdm\n",
        "from sklearn import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFs3d9hlGR0f"
      },
      "source": [
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word.lower())\n",
        "    return tokens\n",
        "train_tagged = train.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['Preprocessed_tweets']), tags=[r.Label]), axis=1)\n",
        "test_tagged = test.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['Preprocessed_tweets']), tags=[r.Label]), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA57f1l7RkNG"
      },
      "source": [
        "import multiprocessing\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7nNTn4JVcQb"
      },
      "source": [
        "\n",
        "\n",
        "# **DBOW MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSqYTIZYSyKN",
        "outputId": "dd036306-bbbc-4307-a1b3-ada6f545167f"
      },
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2118/2118 [00:00<00:00, 1047463.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oAxzoEySx_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9a8ec7-ce13-4b4f-b664-e15be2df8d46"
      },
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2118/2118 [00:00<00:00, 779599.46it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 717977.52it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 750425.40it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1810749.26it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 502718.34it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 901790.26it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 580130.34it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 813585.12it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1876539.05it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1084945.76it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 616912.21it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 970030.12it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 631830.43it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 640947.75it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 609588.68it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 578543.53it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 499495.97it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1206182.74it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 624194.48it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1251202.24it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 636083.05it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1337881.91it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1862376.49it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1076792.23it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 589993.75it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 462660.06it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 947375.05it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 542009.51it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 967073.36it/s]\n",
            "100%|██████████| 2118/2118 [00:00<00:00, 1838099.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.3 s, sys: 770 ms, total: 7.07 s\n",
            "Wall time: 4.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdo_1rxMSxzN"
      },
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei9zF_azqCN8"
      },
      "source": [
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7burWE-YsjP5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YkcKbXb-olsa"
      },
      "source": [
        "# param_grid = { 'max_iter':[100,1000],'penalty' : ['l1','l2'],'C': [0.1, 100, 1000,100000,1000000], \"solver\":['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "# grid_log = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3)\n",
        "# grid_log.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1JG6PODq5Jo"
      },
      "source": [
        "print(grid_log.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8T-3dfJSxhi",
        "outputId": "492b5ef3-2fef-4692-dfe5-71a921c27ba4"
      },
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "logreg = LogisticRegression(n_jobs=-1, C=100, max_iter=100, penalty='l2', solver='newton-cg')\n",
        "pickle.dump(logreg,open('/content/drive/MyDrive/Scraped Tweets/models/dbow.pkl','wb'))\n",
        "logreg=pickle.load(open(\"/content/drive/MyDrive/Scraped Tweets/models/dbow.pkl\", 'rb'))\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "y_pred_train = logreg.predict(X_train)\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "print('Training accuracy %s' % accuracy_score(y_train, y_pred_train))\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy 0.5996222851746931\n",
            "Testing accuracy 0.5339622641509434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlkoaEGj7ZMR",
        "outputId": "5268413a-3053-4271-bb69-7bf69c3e9672"
      },
      "source": [
        "sv_dbow = SVC(C=10, kernel='rbf', gamma=0.0001)\n",
        "sv_dbow.fit(X_train, y_train)\n",
        "y_pred = sv_dbow.predict(X_test)\n",
        "y_pred_train = logreg.predict(X_train)\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "print('Training accuracy %s' % accuracy_score(y_train, y_pred_train))\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy 0.5774315391879131\n",
            "Testing accuracy 0.5452830188679245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkL9l46RVTeL"
      },
      "source": [
        "# **DM MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfhtAjRWSxY_",
        "outputId": "60ffb166-ac87-43e0-e599-3d62b9c5c3c8"
      },
      "source": [
        "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
        "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1123/1123 [00:00<00:00, 684622.59it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q_92hCJSxPw",
        "outputId": "85ad46a3-d7ea-490b-fe61-78231c0760d8"
      },
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dmm.alpha -= 0.002\n",
        "    model_dmm.min_alpha = model_dmm.alpha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1123/1123 [00:00<00:00, 1052089.21it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1248728.36it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1824246.09it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 963823.08it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 755566.79it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 477708.25it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 611476.49it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1109066.02it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 702805.64it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1663794.91it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1680415.05it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1410240.54it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 525868.41it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1501499.33it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 404587.13it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1272683.98it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 949255.02it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1501978.12it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 393369.25it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 639973.29it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 981701.42it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1681614.92it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1181686.75it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1673251.65it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1614188.96it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 442729.90it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1115369.02it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 786344.47it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 332477.12it/s]\n",
            "100%|██████████| 1123/1123 [00:00<00:00, 1546356.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.23 s, sys: 505 ms, total: 6.74 s\n",
            "Wall time: 4.36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvSo9czvSxET",
        "outputId": "c192f839-8bb3-407f-844e-2dbedbfe233a"
      },
      "source": [
        "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
        "logreg.fit(X_train, y_train)\n",
        "pickle.dump(logreg,open('/content/drive/MyDrive/Scraped Tweets/models/dmm.pkl','wb'))\n",
        "logreg=pickle.load(open(\"/content/drive/MyDrive/Scraped Tweets/models/dmm.pkl\", 'rb'))\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy 0.536\n",
            "Testing F1 score: 0.5472821183393265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW0wd0Kg76HI",
        "outputId": "ac5f9d68-9cb0-40ca-b337-6b33ce83e576"
      },
      "source": [
        "sv_dm = SVC(C=10, kernel='rbf', gamma=0.0001)\n",
        "sv_dm.fit(X_train, y_train)\n",
        "y_pred = sv_dbow.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy 0.536\n",
            "Testing F1 score: 0.3740833333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WclGRTU7lCc2"
      },
      "source": [
        "#TFIDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3MBoZ_vhAX1"
      },
      "source": [
        "df[\"tweet_class\"]=df[\"Label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyuVoQe0iSgM"
      },
      "source": [
        "df[\"tweet_class\"]=df[\"tweet_class\"].replace(\"AG_PF\",0)\n",
        "df[\"tweet_class\"]=df[\"tweet_class\"].replace(\"AF_PG\",1)\n",
        "df[\"tweet_class\"]=df[\"tweet_class\"].replace(\"NEUTRAL\",2)\n",
        "df[\"tweet_class\"]=df[\"tweet_class\"].replace(\"PROVOKING\",3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "ij3CKS67oy5W",
        "outputId": "77dce9d6-0a1d-4d57-9b52-caf31b84b226"
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "df.groupby('tweet_class').Text.count().plot.bar(ylim=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldLAB4QxgZvx",
        "outputId": "8c118c92-3d7f-4500-db01-5a0e86cd2a89"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "features = tfidf.fit_transform(df.Text).toarray()\n",
        "labels = df.tweet_class\n",
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1248, 1020)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parA9B1gpbwa"
      },
      "source": [
        "def ConvertListToDictionary(lst):\n",
        "    res_dct = {lst[i]: lst[i + 1] for i in range(0, len(lst), 2)}\n",
        "    return res_dct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jS2rLfcnHZR"
      },
      "source": [
        "tweet_to_id_dict = ConvertListToDictionary([\"AG_PF\",0,\"AF_PG\",1,\"NEUTRAL\",2,\"PROVOKING\",3])\n",
        "id_to_tweet_dict = ConvertListToDictionary([0,\"AG_PF\",1,\"AF_PG\",2,\"NEUTRAL\",3,\"PROVOKING\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfQfQ9MojsoF",
        "outputId": "ef2b969c-09ee-4d0c-fa44-f9c542c4695b"
      },
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "N = 2\n",
        "for label, class_id in sorted(tweet_to_id_dict.items()):\n",
        "  features_chi2 = chi2(features, labels == class_id)\n",
        "  indices = np.argsort(features_chi2[0])\n",
        "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
        "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
        "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
        "  print(\"# '{}':\".format(label))\n",
        "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
        "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# 'AF_PG':\n",
            "  . Most correlated unigrams:\n",
            ". indiatogether\n",
            ". indiaagainstpropaganda\n",
            "  . Most correlated bigrams:\n",
            ". indiaagainstpropaganda https\n",
            ". indiaagainstpropaganda indiatogether\n",
            "# 'AG_PF':\n",
            "  . Most correlated unigrams:\n",
            ". indiaagainstpropaganda\n",
            ". indiatogether\n",
            "  . Most correlated bigrams:\n",
            ". support farmers\n",
            ". indiaagainstpropaganda indiatogether\n",
            "# 'NEUTRAL':\n",
            "  . Most correlated unigrams:\n",
            ". border\n",
            ". meeting\n",
            "  . Most correlated bigrams:\n",
            ". uttar pradesh\n",
            ". verified ðÿ\n",
            "# 'PROVOKING':\n",
            "  . Most correlated unigrams:\n",
            ". retweet\n",
            ". 1984\n",
            "  . Most correlated bigrams:\n",
            ". farmersprotest hailhailfarmers\n",
            ". farmersprotest takebackfarmbills\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--fUQXzCu4mO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Label'],test_size=0.2, random_state = 42)\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(X_train)\n",
        "X_test_counts = count_vect.transform(X_test)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
        "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu5Lqd0dwsUG",
        "outputId": "4962a423-72a8-4d93-cd47-f7c96653f0e0"
      },
      "source": [
        "clf.score(X_train_tfidf,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6603206412825652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07DWqSkVvQ26",
        "outputId": "45b5648a-5746-4bfa-ea2f-afaac507ee75"
      },
      "source": [
        "clf.score(X_test_tfidf,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsjiUsXP8JKw"
      },
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "  \n",
        "\n",
        "# param_grid = {'C': [0.01, 0.1, 1, 10, 100, 1000], \n",
        "#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "#               'kernel': ['linear', 'poly', 'rbf', 'sigmoid']} \n",
        "  \n",
        "# grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "\n",
        "# grid.fit(X_train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LTBJ9mC8Xn2"
      },
      "source": [
        "# print(grid.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ApH6oC8s2J",
        "outputId": "2ef84934-e8d4-410d-e5a1-14fd695c7f48"
      },
      "source": [
        "model_grid_svm = SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
        "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
        "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "    tol=0.001, verbose=False)\n",
        "\n",
        "model_grid_svm.fit(X_train_tfidf,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfIR6ZsP892y",
        "outputId": "53931122-a338-4480-d8e0-153f7feffa0d"
      },
      "source": [
        "print(model_grid_svm.score(X_train_tfidf,y_train))\n",
        "print(model_grid_svm.score(X_test_tfidf,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.996993987975952\n",
            "0.66\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}